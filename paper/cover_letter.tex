% Template: http://www.acm.org/publications/proceedings-template
\documentclass[onecolumn,conference]{IEEEtran}
\usepackage{booktabs} % For formal tables
\usepackage{minted}
\usepackage{graphicx}
\usepackage{arydshln}
\usepackage{subcaption}
\usepackage{times}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}

\begin{document}
\title{Cover Letter: Cudele (Paper 306)}
\maketitle

We thank the reviewers for their hard work and genuinely helpful suggestions.
In addition to this cover letter, we have posted a
\href{https://github.com/michaelsevilla/cudele-popper/blob/master/paper/diff.pdf}{PDF
online} explicitly showing additions in \textcolor{blue}{\textbf{blue}} and
deletions in \textcolor{red}{\textbf{red}}. Three issues were common across
reviewer feedback; Reviewer 1 and 3's comments are addressed in issues II and
III, Reviewer 2's comments are addressed in all issues, and Reviewer 4's
comments are addressed in issues I and II.  

%Use Cases R2, R4
%- Spark discussion R2
%- more emphasis on parallel and distributed computing themes R4
\section*{Issue I: Irrelevant and/or Synthetic Use Cases (Reviewers 2 and 4)}

We re-wrote Section~{\S}V-B to highlight examples from HPC and cloud workloads
that would benefit from using Cudele. For HPC we focus on user home directories
used for experiments and for the cloud we focus on the Hadoop and Spark
runtimes (as suggested by Reviewer 2).  We also added \textbf{Cudele Setup}
headers in Section~{\S}V-B to show which subtree semantics accommodate each
workload and to demonstrate how Cudele might be able to help in these
scenarios.  By showing these setups, we hope to demonstrate that different
applications can use a file system in parallel with different
consistency/durability semantics.  Although we do not actually run the
workloads on our prototype, hopefully our changes show how the use cases, and
the synthetic benchmarks we used to represent them, are indeed relevant to
parallel and distributed computing.

To align the paper to the themes of the conference, we changed Section~{\S}V-A
and Figures 6a, 6b, and 6c to emphasize that decoupled namespaces facilitate
client-driven parallelism, where clients detach subtrees form the global namespace
and do operations in-parallel to their local disk. We also hope that changes to
the use cases above motivate the need for robust distributed storage systems
that can handle today's applications.  So while the paper is storage-centric,
we try to show that the workloads it supports are highly distributed and need a
flexible solution like Cudele.  

%Mixing contributions and future work (R1)
%Statements in Introduction do not align with Evaluation (R1, R2, R3)
%- quantify performance speedups R3
%Evaluation Structure (R2)
%- remove major takeaways and cross refercnes
%Will not address:
%- cost of dynamically changing consistency/durability not presented R1
\section*{Issue II: Structure and Layout of Evaluation (All Reviewers)}

To clarify the evaluation and eliminate some of the confusion due to our
cross-referencing, we:

\begin{itemize}

  \item connected performance gains from the abstract and Section~{\S}I to
Section~{\S}V to clarify speedup/slowdown comparisons and to show how results
are derived; we also re-labeled all graphs with the same metric (throughput
slowdown/speedup) and aligned Section~{\S}V with the graphs in Section~{\S}II.

  \item made experiments self-contained in Sections~{\S}II and~{\S}V by
removing cross-references and adding baseline values so readers can calculate
raw numbers from our speedup/slowdown graphs. We re-ran all experiments to
verify the raw numbers and tweaked the visual representations of the graphs for
clarity (although the actual results are the same).

%  \item explicitly state Cudele setups and subtree configurations in bold in
%Section~{\S}V-B to guide the reader through use cases and the effects of
%different Cudele API configurations.

  \item removed ``major takeaways" from Section~{\S}V and focused on
insights into results by analyzing raw numbers in comparison to hardware
speeds.

  \item removed future work from Section~{\S}I to make the contributions
explicit. We do not attempt to validate or prove any of the statements about
the benefits of changing consistency and durability properties of a subtree
dynamically, such as saving resource provisioning costs.  

  \item clarified confusing terminology in Section~{\S}I: administrator refers
to a person that configures subtrees and client refers to a storage client or
application that interacts with the metadata server. We avoid using the term
``user" except when referring to end-users that interact with home directories
in a file system or the Hadoop/Spark runtime itself.

\end{itemize}

%Experimental Setup (R1, R2, R3)
%- code R1
%- servers, network, storage R1, R3
\section*{Issue III: No Experimental Setup (Reviewers 1, 2, and 3)}

We apologize for the omission of experimental setup and source code details.
For the experimental setup, we describe the cluster setup (hardware, software,
etc.) in Section~{\S}V.  We have also made the infrastructure code available
and added links after each figure to show exactly how experiments are run.
This infrastructure code contains scripts to deploy the system, run
experiments, and gather results.  This process follows the
\href{http://falsifiable.us/}{Popper Convention}, which aims to make research
reproducible.  We also made the source code available online and a link is
provided in Section~{\S}V. Finally, we add details about which tools and
code bases we modified in Section~{\S}IV to address Reviewer 1's questions about
the framework implementation.

\section*{Additional Cosmetic Fixes}
%%Terminology
%%- users vs. clients R2

For Reviewer 1, we fixed user/client terminology in Section~{\S}III,
clarified that the cost of dynamically changing semantics is future work in
Sections~{\S}I and~{\S}III, and added source code pointers in Section~{\S}V.
For Reviewer 2, we removed the major takeaway headings and cross-references in
Section~{\S}V. For Reviewer 3, we quantified speedups with figure annotations
in Section~{\S}V. For Reviewers 1 and 3, we added servers, network, and storage
setups in Section~{\S}V. For Reviewer 4, we added descriptions to each use case
in Section~{\S}V describing how Cudele would work with Spark. 

\end{document}
